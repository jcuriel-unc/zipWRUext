dim(df.whi)
View(df.whi)
length(which(df.whi[,1]==1))
df.bla <- normalize[seq(2, nrow(normalize), 5), ]
df.his <- normalize[seq(3, nrow(normalize), 5), ]
df.asi <- normalize[seq(4, nrow(normalize), 5), ]
df.oth <- normalize[seq(5, nrow(normalize), 5), ]
test_whi_ci <- apply(df.whi, 2, quantile, probs=c(0.025,0.5,0.975))
View(test_whi_ci)
test_whi_ci <- t(test_whi_ci)
test_bla_ci <- apply(df.bla, 2, quantile, probs=c(0.025,0.5,0.975))
test_bla_ci <- t(test_bla_ci) #good, seems to have worked
test_his_ci <- apply(df.his, 2, quantile, probs=c(0.025,0.5,0.975))
test_his_ci <- t(test_his_ci) #good, seems to have worked
test_asi_ci <- apply(df.asi, 2, quantile, probs=c(0.025,0.5,0.975))
test_asi_ci <- t(test_asi_ci) #good, seems to have worked
test_oth_ci <- apply(df.oth, 2, quantile, probs=c(0.025,0.5,0.975))
test_oth_ci <- t(test_oth_ci) #good, seems to have worked
View(test_oth_ci)
class(test_whi_ci)
test_whi_ci <- as.data.frame(test_whi_ci)
names(test_whi_ci)
colnames(test_whi_ci) <- paste0("pred.whi",sep="_",colnames(test_whi_ci))
colnames(test_whi_ci)
colnames(test_bla_ci) <- paste0("pred.bla",sep="_",colnames(test_bla_ci))
colnames(test_his_ci) <- paste0("pred.his",sep="_",colnames(test_his_ci))
colnames(test_asi_ci) <- paste0("pred.asi",sep="_",colnames(test_asi_ci))
colnames(test_oth_ci) <- paste0("pred.oth",sep="_",colnames(test_oth_ci))
wi_data4col <- cbind(wi_data4col,test_whi_ci,test_bla_ci,test_his_ci,test_asi_ci,test_oth_ci)
View(wi_data4col)
wru_aggregate_pres
predNames = c("pred.whi",
"pred.bla", "pred.his", "pred.asi", "pred.oth")
wi_data4col$total_pop <- rowSums(.wi_data4col[predNames],)
wi_data4col$total_pop <- rowSums(wi_data4col[predNames],)
View(wi_data4col)
wi_data4col$total_pop <- rowSums(wi_data4col[predNames])
View(wi_data4col)
match(predNames,names(wi_data4col))
temp_vec<-match(predNames,names(wi_data4col))
normalize <- apply(wi_data4col, 1, function(x) rmultinom(x[8], x[7], x[temp_vec]))
dim(normalize) # 5000  312; num of zip codes preserved; means that the cols are zip codes; should colsum to pop
?rmultinom
wru_cis <- function(df,group_var="zcta5",predNames = c("pred.whi",
"pred.bla", "pred.his", "pred.asi", "pred.oth"),
ci_vec=c(0.025,0.5,0.975)){
colnames(df)[colnames(df) == group_var] <- "group_n"
## collapse the data by the grouping var and sum for the pred name vec
df_col <- df %>% group_by(group_n) %>% select(all_of(predNames)) %>%
summarise(across(where(is.numeric), ~sum(.x, na.rm = T)))
## get the total pop
df_col$total_pop <- rowSums(df_col[predNames]) # get total pop of area
df_col$sample_size = 1000 ## draw 1000 time
## get position of columns
pop_col <- match("total_pop",names(df_col))
samp_size_col = match("sample_size", names(df_col))
pred_name_cols <= match(predNames, names(df_col))
## now get the random sample
output_rmnom <- apply(df_col, 1, function(x) rmultinom(x[samp_size_col], x[pop_col], x[pred_name_cols]))
### now slice by race
df.whi <-  normalize[seq(1, nrow(normalize), 5), ]
df.bla <- normalize[seq(2, nrow(normalize), 5), ]
df.his <- normalize[seq(3, nrow(normalize), 5), ]
df.asi <- normalize[seq(4, nrow(normalize), 5), ]
df.oth <- normalize[seq(5, nrow(normalize), 5), ]
### now, get the confidence intervals
test_whi_ci <- apply(df.whi, 2, quantile, probs=ci_vec)
test_whi_ci <- t(test_whi_ci) #good, seems to have worked
## bla
test_bla_ci <- apply(df.bla, 2, quantile, probs=ci_vec)
test_bla_ci <- t(test_bla_ci) #good, seems to have worked
#his
test_his_ci <- apply(df.his, 2, quantile, probs=ci_vec)
test_his_ci <- t(test_his_ci) #good, seems to have worked
#asi
test_asi_ci <- apply(df.asi, 2, quantile, probs=ci_vec)
test_asi_ci <- t(test_asi_ci) #good, seems to have worked
# oth
test_oth_ci <- apply(df.oth, 2, quantile, probs=ci_vec)
test_oth_ci <- t(test_oth_ci) #good, seems to have worked
### rename the cols
colnames(test_whi_ci) <- paste0("pred.whi",sep="_",colnames(test_whi_ci)) # good, this worked; now repeat
colnames(test_bla_ci) <- paste0("pred.bla",sep="_",colnames(test_bla_ci))
colnames(test_his_ci) <- paste0("pred.his",sep="_",colnames(test_his_ci))
colnames(test_asi_ci) <- paste0("pred.asi",sep="_",colnames(test_asi_ci))
colnames(test_oth_ci) <- paste0("pred.oth",sep="_",colnames(test_oth_ci))
### now I should be ready to merge these
df_col <- cbind(df_col,test_whi_ci,test_bla_ci,test_his_ci,test_asi_ci,test_oth_ci)
### return the df
return(df_col)
}
wi_data4_cis <- wru_cis(wi_data4, group_var = "zcta5")
wru_cis <- function(df,group_var="zcta5",predNames = c("pred.whi",
"pred.bla", "pred.his", "pred.asi", "pred.oth"),
ci_vec=c(0.025,0.5,0.975)){
colnames(df)[colnames(df) == group_var] <- "group_n"
## collapse the data by the grouping var and sum for the pred name vec
df_col <- df %>% group_by(group_n) %>% select(all_of(predNames)) %>%
summarise(across(where(is.numeric), ~sum(.x, na.rm = T)))
## get the total pop
df_col$total_pop <- rowSums(df_col[predNames]) # get total pop of area
df_col$sample_size = 1000 ## draw 1000 time
## get position of columns
pop_col <- match("total_pop",names(df_col))
samp_size_col = match("sample_size", names(df_col))
pred_name_cols <- match(predNames, names(df_col))
## now get the random sample
output_rmnom <- apply(df_col, 1, function(x) rmultinom(x[samp_size_col], x[pop_col], x[pred_name_cols]))
### now slice by race
df.whi <-  normalize[seq(1, nrow(normalize), 5), ]
df.bla <- normalize[seq(2, nrow(normalize), 5), ]
df.his <- normalize[seq(3, nrow(normalize), 5), ]
df.asi <- normalize[seq(4, nrow(normalize), 5), ]
df.oth <- normalize[seq(5, nrow(normalize), 5), ]
### now, get the confidence intervals
test_whi_ci <- apply(df.whi, 2, quantile, probs=ci_vec)
test_whi_ci <- t(test_whi_ci) #good, seems to have worked
## bla
test_bla_ci <- apply(df.bla, 2, quantile, probs=ci_vec)
test_bla_ci <- t(test_bla_ci) #good, seems to have worked
#his
test_his_ci <- apply(df.his, 2, quantile, probs=ci_vec)
test_his_ci <- t(test_his_ci) #good, seems to have worked
#asi
test_asi_ci <- apply(df.asi, 2, quantile, probs=ci_vec)
test_asi_ci <- t(test_asi_ci) #good, seems to have worked
# oth
test_oth_ci <- apply(df.oth, 2, quantile, probs=ci_vec)
test_oth_ci <- t(test_oth_ci) #good, seems to have worked
### rename the cols
colnames(test_whi_ci) <- paste0("pred.whi",sep="_",colnames(test_whi_ci)) # good, this worked; now repeat
colnames(test_bla_ci) <- paste0("pred.bla",sep="_",colnames(test_bla_ci))
colnames(test_his_ci) <- paste0("pred.his",sep="_",colnames(test_his_ci))
colnames(test_asi_ci) <- paste0("pred.asi",sep="_",colnames(test_asi_ci))
colnames(test_oth_ci) <- paste0("pred.oth",sep="_",colnames(test_oth_ci))
### now I should be ready to merge these
df_col <- cbind(df_col,test_whi_ci,test_bla_ci,test_his_ci,test_asi_ci,test_oth_ci)
### return the df
return(df_col)
}
wi_data4_cis <- wru_cis(wi_data4, group_var = "zcta5")
View(wi_data4_cis)
wru_cis <- function(df,group_var="zcta5",predNames = c("pred.whi",
"pred.bla", "pred.his", "pred.asi", "pred.oth"),
ci_vec=c(0.025,0.5,0.975)){
colnames(df)[colnames(df) == group_var] <- "group_n"
## collapse the data by the grouping var and sum for the pred name vec
df_col <- df %>% group_by(group_n) %>% select(all_of(predNames)) %>%
summarise(across(where(is.numeric), ~sum(.x, na.rm = T)))
## get the total pop
df_col$total_pop <- rowSums(df_col[predNames]) # get total pop of area
df_col$sample_size = 1000 ## draw 1000 time
## get position of columns
pop_col <- match("total_pop",names(df_col))
samp_size_col = match("sample_size", names(df_col))
pred_name_cols <- match(predNames, names(df_col))
## now get the random sample
output_rmnom <- apply(df_col, 1, function(x) rmultinom(x[samp_size_col], x[pop_col], x[pred_name_cols]))
### now slice by race
df.whi <-  normalize[seq(1, nrow(normalize), 5), ]
df.bla <- normalize[seq(2, nrow(normalize), 5), ]
df.his <- normalize[seq(3, nrow(normalize), 5), ]
df.asi <- normalize[seq(4, nrow(normalize), 5), ]
df.oth <- normalize[seq(5, nrow(normalize), 5), ]
### now, get the confidence intervals
test_whi_ci <- apply(df.whi, 2, quantile, probs=ci_vec)
test_whi_ci <- t(test_whi_ci) #good, seems to have worked
## bla
test_bla_ci <- apply(df.bla, 2, quantile, probs=ci_vec)
test_bla_ci <- t(test_bla_ci) #good, seems to have worked
#his
test_his_ci <- apply(df.his, 2, quantile, probs=ci_vec)
test_his_ci <- t(test_his_ci) #good, seems to have worked
#asi
test_asi_ci <- apply(df.asi, 2, quantile, probs=ci_vec)
test_asi_ci <- t(test_asi_ci) #good, seems to have worked
# oth
test_oth_ci <- apply(df.oth, 2, quantile, probs=ci_vec)
test_oth_ci <- t(test_oth_ci) #good, seems to have worked
### rename the cols
colnames(test_whi_ci) <- paste0("pred.whi",sep="_",colnames(test_whi_ci)) # good, this worked; now repeat
colnames(test_bla_ci) <- paste0("pred.bla",sep="_",colnames(test_bla_ci))
colnames(test_his_ci) <- paste0("pred.his",sep="_",colnames(test_his_ci))
colnames(test_asi_ci) <- paste0("pred.asi",sep="_",colnames(test_asi_ci))
colnames(test_oth_ci) <- paste0("pred.oth",sep="_",colnames(test_oth_ci))
### now I should be ready to merge these
df_col <- cbind(df_col,test_whi_ci,test_bla_ci,test_his_ci,test_asi_ci,test_oth_ci)
df_col <- subset(df_col, -c(sample_size))
### return the df
return(df_col)
}
wi_data4_cis <- wru_cis(wi_data4, group_var = "zcta5")
wru_cis <- function(df,group_var="zcta5",predNames = c("pred.whi",
"pred.bla", "pred.his", "pred.asi", "pred.oth"),
ci_vec=c(0.025,0.5,0.975)){
colnames(df)[colnames(df) == group_var] <- "group_n"
## collapse the data by the grouping var and sum for the pred name vec
df_col <- df %>% group_by(group_n) %>% select(all_of(predNames)) %>%
summarise(across(where(is.numeric), ~sum(.x, na.rm = T)))
## get the total pop
df_col$total_pop <- rowSums(df_col[predNames]) # get total pop of area
df_col$sample_size = 1000 ## draw 1000 time
## get position of columns
pop_col <- match("total_pop",names(df_col))
samp_size_col = match("sample_size", names(df_col))
pred_name_cols <- match(predNames, names(df_col))
## now get the random sample
output_rmnom <- apply(df_col, 1, function(x) rmultinom(x[samp_size_col], x[pop_col], x[pred_name_cols]))
### now slice by race
df.whi <-  normalize[seq(1, nrow(normalize), 5), ]
df.bla <- normalize[seq(2, nrow(normalize), 5), ]
df.his <- normalize[seq(3, nrow(normalize), 5), ]
df.asi <- normalize[seq(4, nrow(normalize), 5), ]
df.oth <- normalize[seq(5, nrow(normalize), 5), ]
### now, get the confidence intervals
test_whi_ci <- apply(df.whi, 2, quantile, probs=ci_vec)
test_whi_ci <- t(test_whi_ci) #good, seems to have worked
## bla
test_bla_ci <- apply(df.bla, 2, quantile, probs=ci_vec)
test_bla_ci <- t(test_bla_ci) #good, seems to have worked
#his
test_his_ci <- apply(df.his, 2, quantile, probs=ci_vec)
test_his_ci <- t(test_his_ci) #good, seems to have worked
#asi
test_asi_ci <- apply(df.asi, 2, quantile, probs=ci_vec)
test_asi_ci <- t(test_asi_ci) #good, seems to have worked
# oth
test_oth_ci <- apply(df.oth, 2, quantile, probs=ci_vec)
test_oth_ci <- t(test_oth_ci) #good, seems to have worked
### rename the cols
colnames(test_whi_ci) <- paste0("pred.whi",sep="_",colnames(test_whi_ci)) # good, this worked; now repeat
colnames(test_bla_ci) <- paste0("pred.bla",sep="_",colnames(test_bla_ci))
colnames(test_his_ci) <- paste0("pred.his",sep="_",colnames(test_his_ci))
colnames(test_asi_ci) <- paste0("pred.asi",sep="_",colnames(test_asi_ci))
colnames(test_oth_ci) <- paste0("pred.oth",sep="_",colnames(test_oth_ci))
### now I should be ready to merge these
df_col <- cbind(df_col,test_whi_ci,test_bla_ci,test_his_ci,test_asi_ci,test_oth_ci)
### return the df
return(df_col)
}
wi_data4_cis <- wru_cis(wi_data4, group_var = "zcta5")
library("devtools")
library("roxygen2")
library(usethis)
parentDirectory <- dirname(rstudioapi::getActiveDocumentContext()$path)
setwd(parentDirectory)
devtools::install_github("https://github.com/jcuriel-unc/zipWRUext", subdir="zipWRUext2")
library(zipWRUext2)
?wru_cis
wi_data <-  zipWRUext2::wi_data
wi_data2 <- zip_wru(wi_data, state="WISCONSIN",  year1="2010", zip_col="zcta5", surname_field = "lastname")
wi_data2_cis <- wru_cis(wi_data2, group_var = "zcta5")
devtools::install_github("https://github.com/jcuriel-unc/zipWRUext", subdir="zipWRUext2")
library(zipWRUext2)
?zip_wru
wi_data <-  zipWRUext2::wi_data
wi_data2 <- zip_wru(wi_data, state="WISCONSIN",  year1="2010", zip_col="zcta5", surname_field = "lastname")
wi_data2_cis <- wru_cis(wi_data2, group_var = "zcta5")
View(wi_data2_cis)
devtools::install_github("https://github.com/jcuriel-unc/zipWRUext", subdir="zipWRUext2")
?zip_wru
library(zipWRUext2)
?zip_wru
?wru_cis
?wi_data
wi_data <-  zipWRUext2::wi_data
wi_data2 <- zip_wru(wi_data, state="WISCONSIN",  year1="2010", zip_col="zcta5", surname_field = "lastname")
wi_data2_cis <- wru_cis(wi_data2, group_var = "zcta5")
devtools::install_github("https://github.com/jcuriel-unc/zipWRUext", subdir="zipWRUext2")
library(zipWRUext2)
?zip_wru
library(zipWRUext2)
library(wru)
?zip_wru
?wru_cis
wi_data <-  zipWRUext2::wi_data
wi_data2 <- zip_wru(wi_data, state="WISCONSIN",  year1="2010", zip_col="zcta5", surname_field = "lastname")
wi_data2_cis <- wru_cis(wi_data2, group_var = "zcta5")
library("devtools")
library("roxygen2")
library(usethis)
parentDirectory <- dirname(rstudioapi::getActiveDocumentContext()$path)
setwd(parentDirectory)
zcta_acs2020 <- readRDS("zcta_acs2016_2020.rds")
View(zcta_acs2020)
library(zipWRUext2)
all_df <- zipWRUext2::zip_all_census2
View(all_df)
head(all_df)
head(zcta_acs2020)
colnames(zcta_acs2020)[colnames(zcta_acs2020)=="white"] <- "q_whi"
colnames(zcta_acs2020)[colnames(zcta_acs2020)=="black"] <- "q_bla"
colnames(zcta_acs2020)[colnames(zcta_acs2020)=="hispanic"] <- "q_his"
colnames(zcta_acs2020)[colnames(zcta_acs2020)=="asian_pi"] <- "q_asi"
colnames(zcta_acs2020)[colnames(zcta_acs2020)=="other"] <- "q_oth"
colnames(zcta_acs2020)[colnames(zcta_acs2020)=="state"] <- "state_po"
zcta_acs2020 <- subset(zcta_acs2020, select=-c(county,latitude,longitude))
head(all_df)
head(zcta_acs2020)
str(all_df)
zcta_acs2020$year <- "2020"
unique(all_df$type)
zcta_acs2020$type <- "acs"
state_df <- subset(all_df, select = c(state_name,state_po))
state_df <- state_df[!duplicated(state_df$state_name), ]
zcta_acs2020 <- merge(zcta_acs2020, state_df, by="state_po")
zcta_acs2020 <- readRDS("zcta_acs2016_2020.rds")
colnames(zcta_acs2020)[colnames(zcta_acs2020)=="white"] <- "q_whi"
colnames(zcta_acs2020)[colnames(zcta_acs2020)=="black"] <- "q_bla"
colnames(zcta_acs2020)[colnames(zcta_acs2020)=="hispanic"] <- "q_his"
colnames(zcta_acs2020)[colnames(zcta_acs2020)=="asian_pi"] <- "q_asi"
colnames(zcta_acs2020)[colnames(zcta_acs2020)=="other"] <- "q_oth"
### state names
colnames(zcta_acs2020)[colnames(zcta_acs2020)=="state"] <- "state_po"
### drop some of the vars in the acs data
zcta_acs2020 <- subset(zcta_acs2020, select=-c(county,latitude,longitude))
## add on fields
zcta_acs2020$year <- "2020"
zcta_acs2020$type <- "acs"
zcta_acs2020 <- merge(zcta_acs2020, state_df, by="state_po", all.x=T)
View(zcta_acs2020)
state.name
zcta_acs2020$state_name[zcta_acs2020$state_po=="DC"] <- "WASHINGTON DC"
file2021 <- list.files("2021")
file2021
ga_wd <- dirname(rstudioapi::getActiveDocumentContext()$path)
setwd(ga_wd)
file2021 <- list.files("2021")
file2021 <- file2021[grep(".csv",file2021)]
file2021
file2021 <- list.files("2021", full.names = T)
file2021 <- file2021[grep(".csv",file2021)]
zip_acs_new <- read.csv(file2021)
## change races
colnames(zip_acs_new)[colnames(zip_acs_new)=="SE_A04001_001"] <- "total_pop"
colnames(zip_acs_new)[colnames(zip_acs_new)=="SE_A04001_003"] <- "white"
colnames(zip_acs_new)[colnames(zip_acs_new)=="SE_A04001_004"] <- "black"
colnames(zip_acs_new)[colnames(zip_acs_new)=="SE_A04001_010"] <- "hispanic"
zip_acs_new$asian_pi <- zip_acs_new$SE_A04001_006 + zip_acs_new$SE_A04001_007
zip_acs_new <- subset(zip_acs_new, total_pop >= 0)
zip_acs_new$other <- zip_acs_new$SE_A04001_005+zip_acs_new$SE_A04001_008+zip_acs_new$SE_A04001_009
### now, subset
zip_acs_new <- subset(zip_acs_new, Geo_STUSAB=="us")
zip_acs_new$zcta5 <- str_pad(zip_acs_new$Geo_ZCTA5, pad="0", side="left",width=5)
zip_acs_new <- subset(zip_acs_new, select = c(zcta5,total_pop,white,black,hispanic,asian_pi,other))
### now, try to merge on the national zip code data
zcta_db <- read.csv('zip_code_database.csv')
#head(zcta_db)
zcta_db$zip <- str_pad(zcta_db$zip, pad="0", side="left",width=5)
zcta_db <- subset(zcta_db, select=c(zip,state,county,latitude ,longitude))
### now, merge
zip_acs_new_master <- merge(zip_acs_new, zcta_db, by.x="zcta5",by.y="zip",all.x=T,all.y=F)
sum(is.na(zip_acs_new_master$state)) #good, nothing missing
sum(is.na(zip_acs_new_master$latitude))
### now, create the necessary weight r_whi fields and such
zip_acs_new_master <- zip_acs_new_master %>%
group_by(state) %>%
mutate(r_whi=white/sum(white),r_bla=black/(sum(black)),r_his=hispanic/sum(hispanic), r_asi=asian_pi/sum(asian_pi),
r_oth=other/sum(other))
library(stringi)
library(stringr)
zip_acs_new <- read.csv(file2021)
## change races
colnames(zip_acs_new)[colnames(zip_acs_new)=="SE_A04001_001"] <- "total_pop"
colnames(zip_acs_new)[colnames(zip_acs_new)=="SE_A04001_003"] <- "white"
colnames(zip_acs_new)[colnames(zip_acs_new)=="SE_A04001_004"] <- "black"
colnames(zip_acs_new)[colnames(zip_acs_new)=="SE_A04001_010"] <- "hispanic"
zip_acs_new$asian_pi <- zip_acs_new$SE_A04001_006 + zip_acs_new$SE_A04001_007
zip_acs_new <- subset(zip_acs_new, total_pop >= 0)
zip_acs_new$other <- zip_acs_new$SE_A04001_005+zip_acs_new$SE_A04001_008+zip_acs_new$SE_A04001_009
### now, subset
zip_acs_new <- subset(zip_acs_new, Geo_STUSAB=="us")
zip_acs_new$zcta5 <- str_pad(zip_acs_new$Geo_ZCTA5, pad="0", side="left",width=5)
zip_acs_new <- subset(zip_acs_new, select = c(zcta5,total_pop,white,black,hispanic,asian_pi,other))
### now, try to merge on the national zip code data
zcta_db <- read.csv('zip_code_database.csv')
#head(zcta_db)
zcta_db$zip <- str_pad(zcta_db$zip, pad="0", side="left",width=5)
zcta_db <- subset(zcta_db, select=c(zip,state,county,latitude ,longitude))
zip_acs_new_master <- merge(zip_acs_new, zcta_db, by.x="zcta5",by.y="zip",all.x=T,all.y=F)
sum(is.na(zip_acs_new_master$state)) #good, nothing missing
sum(is.na(zip_acs_new_master$latitude))
zip_acs_new_master <- zip_acs_new_master %>%
group_by(state) %>%
mutate(r_whi=white/sum(white),r_bla=black/(sum(black)),r_his=hispanic/sum(hispanic), r_asi=asian_pi/sum(asian_pi),
r_oth=other/sum(other))
all_df <- zipWRUext2::zip_all_census2
state_df <- subset(all_df, select = c(state_name,state_po))
state_df <- state_df[!duplicated(state_df$state_name), ]
library(foreign)
library(rgdal)
library(sp)
library(dplyr)
library(wru)
library(ggplot2)
library(gridExtra)
library(stringi)
library(stringr)
library(tidyverse)
library(ggpubr)###
library(data.table)
library(readxl)
zip_acs_new_master <- merge(zip_acs_new, zcta_db, by.x="zcta5",by.y="zip",all.x=T,all.y=F)
sum(is.na(zip_acs_new_master$state)) #good, nothing missing
sum(is.na(zip_acs_new_master$latitude))
zip_acs_new_master <- zip_acs_new_master %>%
group_by(state) %>%
mutate(r_whi=white/sum(white),r_bla=black/(sum(black)),r_his=hispanic/sum(hispanic), r_asi=asian_pi/sum(asian_pi),
r_oth=other/sum(other))
### clean the data here to match the wru data
colnames(zip_acs_new_master)[colnames(zip_acs_new_master)=="white"] <- "q_whi"
colnames(zip_acs_new_master)[colnames(zip_acs_new_master)=="black"] <- "q_bla"
colnames(zip_acs_new_master)[colnames(zip_acs_new_master)=="hispanic"] <- "q_his"
colnames(zip_acs_new_master)[colnames(zip_acs_new_master)=="asian_pi"] <- "q_asi"
colnames(zip_acs_new_master)[colnames(zip_acs_new_master)=="other"] <- "q_oth"
### state names
colnames(zip_acs_new_master)[colnames(zip_acs_new_master)=="state"] <- "state_po"
### drop some of the vars in the acs data
zip_acs_new_master <- subset(zip_acs_new_master, select=-c(county,latitude,longitude))
## add on fields
zip_acs_new_master$year <- "2021"
zip_acs_new_master$type <- "acs"
##merge on the state data
zip_acs_new_master <- merge(zip_acs_new_master, state_df, by="state_po", all.x=T)
zip_acs_new_master$state_name[zip_acs_new_master$state_po=="DC"] <- "WASHINGTON DC"
View(zip_acs_new_master)
dim(all_df)
saveRDS(zip_acs_new_master, "zcta_acs2017_2021.rds")
file2019 <- list.files("2019", full.names = T)
file2019 <- file2019[grep(".csv",file2019)]
file2019
zip_acs_new <- read.csv(file2019)
## change races
colnames(zip_acs_new)[colnames(zip_acs_new)=="SE_A04001_001"] <- "total_pop"
colnames(zip_acs_new)[colnames(zip_acs_new)=="SE_A04001_003"] <- "white"
colnames(zip_acs_new)[colnames(zip_acs_new)=="SE_A04001_004"] <- "black"
colnames(zip_acs_new)[colnames(zip_acs_new)=="SE_A04001_010"] <- "hispanic"
zip_acs_new$asian_pi <- zip_acs_new$SE_A04001_006 + zip_acs_new$SE_A04001_007
zip_acs_new <- subset(zip_acs_new, total_pop >= 0)
zip_acs_new$other <- zip_acs_new$SE_A04001_005+zip_acs_new$SE_A04001_008+zip_acs_new$SE_A04001_009
### now, subset
zip_acs_new <- subset(zip_acs_new, Geo_STUSAB=="us")
zip_acs_new$zcta5 <- str_pad(zip_acs_new$Geo_ZCTA5, pad="0", side="left",width=5)
zip_acs_new <- subset(zip_acs_new, select = c(zcta5,total_pop,white,black,hispanic,asian_pi,other))
### now, try to merge on the national zip code data
zcta_db <- read.csv('zip_code_database.csv')
#head(zcta_db)
zcta_db$zip <- str_pad(zcta_db$zip, pad="0", side="left",width=5)
zcta_db <- subset(zcta_db, select=c(zip,state,county,latitude ,longitude))
### now, merge
zip_acs_new_master <- merge(zip_acs_new, zcta_db, by.x="zcta5",by.y="zip",all.x=T,all.y=F)
sum(is.na(zip_acs_new_master$state)) #good, nothing missing
sum(is.na(zip_acs_new_master$latitude))
### now, create the necessary weight r_whi fields and such
zip_acs_new_master <- zip_acs_new_master %>%
group_by(state) %>%
mutate(r_whi=white/sum(white),r_bla=black/(sum(black)),r_his=hispanic/sum(hispanic), r_asi=asian_pi/sum(asian_pi),
r_oth=other/sum(other))
### clean the data here to match the wru data
colnames(zip_acs_new_master)[colnames(zip_acs_new_master)=="white"] <- "q_whi"
colnames(zip_acs_new_master)[colnames(zip_acs_new_master)=="black"] <- "q_bla"
colnames(zip_acs_new_master)[colnames(zip_acs_new_master)=="hispanic"] <- "q_his"
colnames(zip_acs_new_master)[colnames(zip_acs_new_master)=="asian_pi"] <- "q_asi"
colnames(zip_acs_new_master)[colnames(zip_acs_new_master)=="other"] <- "q_oth"
### state names
colnames(zip_acs_new_master)[colnames(zip_acs_new_master)=="state"] <- "state_po"
### drop some of the vars in the acs data
zip_acs_new_master <- subset(zip_acs_new_master, select=-c(county,latitude,longitude))
## add on fields
zip_acs_new_master$year <- "2019"
zip_acs_new_master$type <- "acs"
zip_acs_new_master <- merge(zip_acs_new_master, state_df, by="state_po", all.x=T)
zip_acs_new_master$state_name[zip_acs_new_master$state_po=="DC"] <- "WASHINGTON DC"
View(zip_acs_new_master)
saveRDS(zip_acs_new_master, "zcta_acs2015_2019.rds")
zcta_acs2020 <- readRDS("2020/zcta_acs2016_2020.rds")
## clean column names for q_
colnames(zcta_acs2020)[colnames(zcta_acs2020)=="white"] <- "q_whi"
colnames(zcta_acs2020)[colnames(zcta_acs2020)=="black"] <- "q_bla"
colnames(zcta_acs2020)[colnames(zcta_acs2020)=="hispanic"] <- "q_his"
colnames(zcta_acs2020)[colnames(zcta_acs2020)=="asian_pi"] <- "q_asi"
colnames(zcta_acs2020)[colnames(zcta_acs2020)=="other"] <- "q_oth"
### state names
colnames(zcta_acs2020)[colnames(zcta_acs2020)=="state"] <- "state_po"
### drop some of the vars in the acs data
zcta_acs2020 <- subset(zcta_acs2020, select=-c(county,latitude,longitude))
## add on fields
zcta_acs2020$year <- "2020"
zcta_acs2020$type <- "acs"
### state_df
state_df <- subset(all_df, select = c(state_name,state_po))
state_df <- state_df[!duplicated(state_df$state_name), ]
## now merge on
zcta_acs2020 <- merge(zcta_acs2020, state_df, by="state_po", all.x=T)
zcta_acs2020$state_name[zcta_acs2020$state_po=="DC"] <- "WASHINGTON DC"
saveRDS(zcta_acs2020, "zcta_acs2016_2020.rds")
View(zcta_acs2020)
parentDirectory <- dirname(rstudioapi::getActiveDocumentContext()$path)
setwd(parentDirectory)
list.files()
zip_acs2019 <- readRDS("zcta_acs2015_2019.rds")
zip_acs2020 <- readRDS("zcta_acs2016_2020.rds")
zip_acs2021 <- readRDS("zcta_acs2017_2021.rds")
list.files("data-raw")
setwd("zipWRUext2")
list.files("data-raw")
master_zcta_df <- readRDS("data-raw/master_zcta_bisg_data.rds")
View(master_zcta_df)
master_zcta_df <- rbind(master_zcta_df,zip_acs2019,zip_acs2020,zip_acs2021)
list.files("data")
save(master_zcta_df, file = "data/zip_all_census2.rda")
document()
